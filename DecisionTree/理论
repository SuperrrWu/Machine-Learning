决策树(DecisionTree)
决策树是一个类似于流程图的树结构；其中，每个结点表示在一个属性上的测试，每一个分支代表一个属性输出。

熵(entropy)概念：
一条信息的信息量大小和它的不确定性有直接的关系，要搞清楚一件非常非常不确定的事情，或者是我们一无所知的事情，需要了解大量信息

例子：猜世界杯冠军，假如一无所知，需要猜测多少次？

比特(bit)来衡量信息的多少


     -(p1*log(p1)+p2*log(p2)+.....+pn*log(p32))

      H(X)=-ΣP(x)log2(p(x))
      
决策树归纳算法(ID3)

选择属性判断结点（为什么要把什么属性放在根结点，如何构建决策树）

信息获取量(Information Gain):

    Gain(A)=
    
    
    假设结果有9个yes，5个no。
    
    那么不管所有信息，那么info[Result]=-(9/14)*log2(9/14)-(5/14)*log2(5/14)=0.94(bits)
    
    假如有其他的我们另行计算。
    
    类似，Gain(income)=0.029,Gain(student)=0.151,Gain(creadit_rating)=0.048
    
    所以，选择age作为第一个根结点,同理选择其他结点。
    
